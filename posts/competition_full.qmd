---
title: "지역사회 문제해결형 빅데이터/AI활용 공모전"
author: "Sungil Park"
date: "2023/11/25"
description: "대전시 대중교통 통행수요 예측"
editor_options: 
  chunk_output_type: inline
toc: true
---

```{r} 

```


## Envirionments

| Hardware | Name / Version | 
|:------|:-----|
| CPU      | Ryzen 5800x |
| RAM      | 8G 25600 * 2 |
| GPU      | Radeon RX 570 |
| OS   | UBUNTU 22.04 LTS |

| Software | Name / Version | 
|:------|:-----|
| Python      | 3.10 |
| Sckit-Learn | 1.2.2 |
| Tensorflow | 2.15.0 |
| Keras | 2.15.0 |
| XGBoost | 1.7.6 |
| LightGBM | 3.3.5 |
| CatBoost | 1.2.2 |
| AutoGluon | 0.8.2 |




## Packages

```{python, include = FALSE} 
import numpy as np
import pandas as pd
import geopandas as gpd
from shapely.geometry import Point

from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer 

from autogluon.tabular import TabularDataset, TabularPredictor
from sklearn.metrics import mean_absolute_error

import warnings
warnings.filterwarnings("ignore")
```

```{python, eval = FALSE} 
import numpy as np
import pandas as pd
import geopandas as gpd
from shapely.geometry import Point

from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer 

from autogluon.tabular import TabularDataset, TabularPredictor
from sklearn.metrics import mean_absolute_error

import warnings
warnings.filterwarnings("ignore")
```

## Datasets

### Load Datasets

 - Add `DATETIME` datetime type

```{python} 
train = pd.read_csv("competition_data/train_data_modified.csv")
test = pd.read_csv("competition_data/test_data_modified.csv")

train['TIME'] = train['TIME'].apply(lambda x: str(x).zfill(2))
train['DATETIME'] = pd.to_datetime(train['DATE'] + ' ' + train['TIME'].astype(str), format='%Y-%m-%d %H')

test['TIME'] = test['TIME'].apply(lambda x: str(x).zfill(2))
test['DATETIME'] = pd.to_datetime(test['DATE'] + ' ' + test['TIME'].astype(str), format='%Y-%m-%d %H')
```

### Load Additional Datasets

#### Demographic tile data
 
 - Replace NA with 0

 - Convert to lat-lon coordinate

 - Add `centroid` as numeric value

```{python} 
tile = gpd.read_file("competition_data/nlsp_020001001.shp", encoding = "utf-8")

tile = tile.iloc[:,[0,2,3]]
tile.fillna(0,inplace=True)
tile = gpd.GeoDataFrame(tile, geometry='geometry')
tile = tile.to_crs(epsg=4326)
tile[['longitude', 'latitude']] = tile["geometry"].centroid.astype(str).str.extract(r'POINT \(([^ ]+) ([^ ]+)\)', expand=True)
tile["latitude"] ,tile["longitude"] = tile["latitude"].astype(float),tile["longitude"].astype(float)
```

#### Bus station location data

 - Add `geometry` Point
 
 - Extract data inside `tile` data for optimization

 - Merge data with `tile` data for `bus stop count` per tile

```{python} 
busstop_loc = pd.read_csv("competition_data/getStaionByRouteAll.txt", delimiter="\t")

busstop_loc.columns = ['BUSSTOP_NM', 'BUS_STOP_ID', 'lat', 'lon']
busstop_loc['geometry'] = [Point(lon, lat) for lon, lat in zip(busstop_loc['lon'], busstop_loc['lat'])]
busstop_loc = gpd.GeoDataFrame(busstop_loc, geometry="geometry", crs='EPSG:4326')
busstop_loc = busstop_loc[(busstop_loc["lon"] > tile["longitude"].min()) & 
                          (busstop_loc["lon"] < tile["longitude"].max()) &
                          (busstop_loc["lat"] > tile["latitude"].min()) &
                          (busstop_loc["lat"] < tile["latitude"].max())]
busstop_loc["busstop_cnt"] = 1

a = gpd.sjoin(tile,busstop_loc,how="left").groupby("gid").sum().reset_index()[["gid","busstop_cnt"]]
tile = pd.merge(tile,a,how="left",on="gid")
```

<iframe src="competition_data/busstop_cnt.html" width="800" height="600"></iframe>



## Split data

 - Split train dataset for evaluate models

 - Split a week in July and August into test data (8:2 ratio)

```{python} 
test_set = pd.concat([train[(train["DATETIME"] >= "2023-07-17 00:00:00") & (train["DATETIME"] <= "2023-07-23 23:00:00")],
                     train[(train["DATETIME"] >= "2023-08-18 00:00:00") & (train["DATETIME"] <= "2023-08-24 23:00:00")]])

train_set = train.drop(test_set.index)

X_train = train_set.drop(["RIDE_DEMAND"],axis=1)
y_train = train_set[["RIDE_DEMAND"]]

X_test = test_set.drop(["RIDE_DEMAND"],axis=1)
y_test = test_set[["RIDE_DEMAND"]]

X_train.shape, X_test.shape
```

## Preprocessing, Standard scaling & OneHotEncoding

 - Merge with `tile` information data

 - Convert `TIME` to numeric

 - Add 'TIME_sin' for time periodicity

 - Add `YEAR`,`MONTH`, `DATE`, `DAY_OF_WEEK`


```{python} 
class Transformer(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        return self
    
    def transform(self, X, y=None):
        X = pd.merge(X, tile, on='gid', how='left')
        X["TIME"] = X["TIME"].astype(int)
        X["TIME_sin"] = X["TIME"].apply(lambda x: abs(np.sin(x*(np.pi/23))))
        X["YEAR"] = X["DATETIME"].dt.year
        X["MONTH"] = X["DATETIME"].dt.month
        X["DATE"] = X["DATETIME"].dt.day        
        X['DAY_OF_WEEK'] = X['DATETIME'].dt.day_name()
        return X

list_cat = ['gid', 'DAY_OF_WEEK']
list_num = ['TIME', 'ALIGHT_DEMAND', 'MONTH', 'busstop_cnt', 'DATE', 'val']

transformer = Transformer()

preprocessor = ColumnTransformer(
    transformers=[
        ("num", StandardScaler(), list_num),
        ("cat", OneHotEncoder(), list_cat),
    ],
)

pipeline = Pipeline([
    ('transformer', transformer),
    ('preprocessor', preprocessor),
])

X_train_prep_matrix = pipeline.fit_transform(X_train)
X_test_prep_matrix = pipeline.fit_transform(X_test)
```

## Convert output type

 - prepared train date to fitting model

 - CSR Matrix -> DataFrame

```{python} 
feature_names = preprocessor.get_feature_names_out()

X_train_prep_df = pd.DataFrame(X_train_prep_matrix.toarray(), columns=feature_names)
X_test_prep_df = pd.DataFrame(X_test_prep_matrix.toarray(), columns=feature_names)

X_train_prep_df.head()
```


## Evaluate models

### ML models

#### Randomforest

```{python, eval = FALSE} 
from sklearn.ensemble import RandomForestRegressor

forest_reg = RandomForestRegressor(random_state = 2023)
forest_reg.fit(X_train_prep_df,y_train)

forest_pred = forest_reg.predict(X_test_prep_df)
forest_mae = mean_absolute_error(y_test,forest_pred)
forest_mae
```

#### XGBoost

```{python, eval = FALSE} 
import xgboost

xgb_reg = xgboost.XGBRegressor(objective='reg:squarederror',n_estimators=100,random_state = 2023)
xgb_reg.fit(X_train_prep_df,y_train)

xgb_pred = xgb_reg.predict(X_test_prep_df)
xgb_mae = mean_absolute_error(y_test,xgb_pred)
xgb_mae
```

#### LightGBM

```{python, eval = FALSE} 
from lightgbm import LGBMRegressor

lgb_reg = LGBMRegressor()
lgb_reg.fit(X_train_prep_df, y_train)

lgb_pred = lgb_reg.predict(X_test_prep_df)
lgb_mae = mean_absolute_error(y_test,lgb_pred)
lgb_mae
```


#### CatBoost

```{python, eval = FALSE} 
import catboost as cb
cb_reg = cb.CatBoostRegressor()
cb_reg.fit(X_train_prep_df,y_train)

cb_pred = cb_reg.predict(X_test_prep_df)
cb_mae = mean_absolute_error(y_test,cb_pred)
cb_mae
```


### Some DL

#### Packages
```{python} 
import tensorflow as tf
import sklearn
from tensorflow import keras
```

#### Model_1 (4 Layer * 30 Neurons)

```{python, eval = FALSE} 
tf.keras.backend.clear_session()
tf.random.set_seed(42)

normalization_layer = tf.keras.layers.Normalization()

layer1 = tf.keras.layers.Dense(30, activation="relu")
layer2 = tf.keras.layers.Dense(30, activation="relu")
layer3 = tf.keras.layers.Dense(30, activation="relu")
layer4 = tf.keras.layers.Dense(30, activation="relu")

output_layer = tf.keras.layers.Dense(1)


input_ = tf.keras.layers.Input(shape=X_train_prep_df.shape[1:])
normalized = normalization_layer(input_)

hidden1 = layer1(normalized)
hidden2 = layer2(hidden1)
hidden3 = layer3(hidden2)
hidden4 = layer4(hidden3)

output = output_layer(hidden4)

model_1 = tf.keras.Model(inputs=[input_], outputs=[output])

model_1.summary()
```

```{python, eval = FALSE} 
optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)

model_1.compile(loss="mae", optimizer=optimizer, metrics=["RootMeanSquaredError"])

normalization_layer.adapt(X_train_prep_df)
```

```{python, eval = FALSE} 
history_1 = model_1.fit(X_train_prep_df, y_train, epochs=100)
```

```{python, eval = FALSE} 
mod_1_pred = model_1.predict(X_test_prep_df)
mod_1_mae = mean_absolute_error(y_test,mod_1_pred)
mod_1_mae
```


#### Model_2 (40 - 40 - 20 - 10)

```{python, eval = FALSE} 
tf.keras.backend.clear_session()
tf.random.set_seed(42)

normalization_layer = tf.keras.layers.Normalization()

layer1 = tf.keras.layers.Dense(40, activation="relu")
layer2 = tf.keras.layers.Dense(40, activation="relu")
layer3 = tf.keras.layers.Dense(20, activation="relu")
layer4 = tf.keras.layers.Dense(10, activation="relu")

output_layer = tf.keras.layers.Dense(1)


input_ = tf.keras.layers.Input(shape=X_train_prep_df.shape[1:])
normalized = normalization_layer(input_)

hidden1 = layer1(normalized)
hidden2 = layer2(hidden1)
hidden3 = layer3(hidden2)
hidden4 = layer4(hidden3)

output = output_layer(hidden4)

model_2 = tf.keras.Model(inputs=[input_], outputs=[output])

model_2.summary()
```

```{python, eval = FALSE} 
optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)

model_2.compile(loss="mae", optimizer=optimizer, metrics=["RootMeanSquaredError"])

normalization_layer.adapt(X_train_prep_df)
```

```{python, eval = FALSE} 
history_2 = model_2.fit(X_train_prep_df, y_train, epochs=100)
```

```{python, eval = FALSE} 
mod_2_pred = model_2.predict(X_test_prep_df)
mod_2_mae = mean_absolute_error(y_test,mod_2_pred)
mod_2_mae
```

### AutoGluon

#### Preprocessing for AutoGluon

```{python, eval = FALSE} 
class Transformer_ag(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        return self
    
    def transform(self, X, y=None):
        X = pd.merge(X, tile, on='gid', how='left')
        X["TIME"] = X["TIME"].astype(int)
        X["TIME_sin"] = X["TIME"].apply(lambda x: abs(np.sin(x*(np.pi/23))))
        X["YEAR"] = X["DATETIME"].dt.year
        X["MONTH"] = X["DATETIME"].dt.month
        X["DATE"] = X["DATETIME"].dt.day        
        X['DAY_OF_WEEK'] = X['DATETIME'].dt.day_name()
        return X

transformer_ag = Transformer_ag()

train_set_ag = transformer_ag.fit_transform(train_set)
test_set_ag = transformer_ag.fit_transform(test_set)

X_train_ag = train_set_ag.drop(["RIDE_DEMAND"],axis=1)
y_train_ag = train_set_ag[["RIDE_DEMAND"]]

X_test_ag = test_set_ag.drop(["RIDE_DEMAND"],axis=1)
y_test_ag = test_set_ag[["RIDE_DEMAND"]]

train_set_ag.head()
```

#### Default parameters

```{python, eval = FALSE} 
ag_reg_default = TabularPredictor(label = 'RIDE_DEMAND', problem_type = 'regression', eval_metric = 'mae', path = './ag_reg_default') 

ag_reg_default.fit(train_data = train_set_ag, verbosity = 2)

ag_default_pred = ag_reg_default.predict(X_test_ag)
ag_default_mae = mean_absolute_error(y_test, ag_default_pred)
ag_default_mae
```

#### presets = "best_quality", autostack = True

```{python, eval = FALSE} 
ag_reg_best = TabularPredictor(label = 'RIDE_DEMAND', problem_type = 'regression', eval_metric = 'mae', path = './ag_reg_best') 

ag_reg_best.fit(train_data = train_set_ag, verbosity = 2, preset = , autostack = )

ag_best_pred = ag_reg_best.predict(X_test_ag)
ag_best_mae = mean_absolute_error(y_test, ag_best_pred)
ag_best_mae
```

#### bag_5 stack_1

```{python, eval = FALSE} 
ag_reg_5_1 = TabularPredictor(label = 'RIDE_DEMAND', problem_type = 'regression', eval_metric = 'mae', path = './ag_reg_5_1') 

ag_reg_5_1.fit(train_data = train_set_ag, presets = 'best_quality', auto_stack = True, 
              fit_weighted_ensemble = True, verbosity = 2, 
              num_bag_folds = 5, num_bag_sets = 1, num_stack_levels = 1)

ag_5_1 = ag_reg_5_1.predict(X_test_ag)
ag_5_1_mae = mean_absolute_error(y_test, ag_5_1)
ag_5_1_mae
```

#### bag_7 stack_1

```{python, eval = FALSE} 
ag_reg_7_1 = TabularPredictor(label = 'RIDE_DEMAND', problem_type = 'regression', eval_metric = 'mae', path = './ag_reg_7_1') 

ag_reg_7_1.fit(train_data = train_set_ag, presets = 'best_quality', auto_stack = True, 
              fit_weighted_ensemble = True, verbosity = 2, 
              num_bag_folds = 7, num_bag_sets = 1, num_stack_levels = 1)

ag_7_1 = ag_reg_7_1.predict(X_test_ag)
ag_7_1_mae = mean_absolute_error(y_test, ag_7_1)
ag_7_1_mae
```

#### bag_10 stack_1

```{python, eval = FALSE} 
ag_reg_10_1 = TabularPredictor(label = 'RIDE_DEMAND', problem_type = 'regression', eval_metric = 'mae', path = './ag_reg_10_1') 

ag_reg_10_1.fit(train_data = train_set_ag, presets = 'best_quality', auto_stack = True, 
              fit_weighted_ensemble = True, verbosity = 2, 
              num_bag_folds = 10, num_bag_sets = 1, num_stack_levels = 1)

ag_10_1 = ag_reg_10_1.predict(X_test_ag)
ag_10_1_mae = mean_absolute_error(y_test, ag_10_1)
ag_10_1_mae
```

#### bag_5 stack_2

```{python, eval = FALSE} 
ag_reg_5_2 = TabularPredictor(label = 'RIDE_DEMAND', problem_type = 'regression', eval_metric = 'mae', path = './ag_reg_5_2') 

ag_reg_5_2.fit(train_data = train_set_ag, presets = 'best_quality', auto_stack = True, 
              fit_weighted_ensemble = True, verbosity = 2, 
              num_bag_folds = 5, num_bag_sets = 1, num_stack_levels = 2)

ag_5_2 = ag_reg_5_2.predict(X_test_ag)
ag_5_2_mae = mean_absolute_error(y_test, ag_5_2)
ag_5_2_mae
```

#### bag_7 stack_2

```{python, eval = FALSE} 
ag_reg_7_2 = TabularPredictor(label = 'RIDE_DEMAND', problem_type = 'regression', eval_metric = 'mae', path = './ag_reg_7_2') 

ag_reg_7_2.fit(train_data = train_set_ag, presets = 'best_quality', auto_stack = True, 
              fit_weighted_ensemble = True, verbosity = 2, 
              num_bag_folds = 7, num_bag_sets = 1, num_stack_levels = 2)

ag_7_2 = ag_reg_7_2.predict(X_test_ag)
ag_7_2_mae = mean_absolute_error(y_test, ag_7_2)
ag_7_2_mae
```

#### bag_10 stack_2

```{python, eval = FALSE} 
ag_reg_10_2 = TabularPredictor(label = 'RIDE_DEMAND', problem_type = 'regression', eval_metric = 'mae', path = './ag_reg_10_2') 

ag_reg_10_2.fit(train_data = train_set_ag, presets = 'best_quality', auto_stack = True, 
              fit_weighted_ensemble = True, verbosity = 2, 
              num_bag_folds = 10, num_bag_sets = 1, num_stack_levels = 2)

ag_10_2 = ag_reg_10_2.predict(X_test_ag)
ag_10_2_mae = mean_absolute_error(y_test, ag_10_2)
ag_10_2_mae
```

#### bag_5 stack_3

```{python, eval = FALSE} 
ag_reg_5_3 = TabularPredictor(label = 'RIDE_DEMAND', problem_type = 'regression', eval_metric = 'mae', path = './ag_reg_5_3') 

ag_reg_5_3.fit(train_data = train_set_ag, presets = 'best_quality', auto_stack = True, 
              fit_weighted_ensemble = True, verbosity = 2, 
              num_bag_folds = 5, num_bag_sets = 1, num_stack_levels = 3)

ag_5_3 = ag_reg_5_3.predict(X_test_ag)
ag_5_3_mae = mean_absolute_error(y_test, ag_5_3)
ag_5_3_mae
```

#### bag_7 stack_3

```{python, eval = FALSE} 
ag_reg_7_3 = TabularPredictor(label = 'RIDE_DEMAND', problem_type = 'regression', eval_metric = 'mae', path = './ag_reg_7_3') 

ag_reg_7_3.fit(train_data = train_set_ag, presets = 'best_quality', auto_stack = True, 
              fit_weighted_ensemble = True, verbosity = 2, 
              num_bag_folds = 7, num_bag_sets = 1, num_stack_levels = 3)

ag_7_3 = ag_reg_7_3.predict(X_test_ag)
ag_7_3_mae = mean_absolute_error(y_test, ag_7_3)
ag_7_3_mae
```

#### bag_10 stack_3

```{python, eval = FALSE} 
ag_reg_10_3 = TabularPredictor(label = 'RIDE_DEMAND', problem_type = 'regression', eval_metric = 'mae', path = './ag_reg_10_3') 

ag_reg_10_3.fit(train_data = train_set_ag, presets = 'best_quality', auto_stack = True, 
              fit_weighted_ensemble = True, verbosity = 2, 
              num_bag_folds = 10, num_bag_sets = 1, num_stack_levels = 3)

ag_10_3 = ag_reg_10_3.predict(X_test_ag)
ag_10_3_mae = mean_absolute_error(y_test, ag_10_3)
ag_10_3_mae
```

## Summary

| Model | MAE (Test_set/Pred) | fitting time |
|:------:|:-----|------:|
| RandomForest      | 5.1073 |    14m 32s |
| XGBoost     | 7.0586  |   01m 50s |
| LightGBM | 7.76932  | 3.7s |
| CatBoost |6.4667  | 16s |
| DL Model_1 | 5.3349  |  20m ~ |
| DL Model_2 | 5.2322 |   20m ~ |
| AG_Default | 5.15  |  20m ~ |
| AG_best_quality | 3.9 |  5H ~ |
| AG_5_1 | 5.284 |   5H ~ |
| AG_7_1  | 5.2481 |  5H ~ |
| AG_10_1  | 5.27| 5H ~ |
| AG_5_2  |5.284 |   5H ~ |
| AG_7_2  | 5.2309 |  5H ~ |
| AG_10_2 |  5.27|   5H ~ |
| AG_5_3  | 5.284 |     5H ~ |
| AG_7_3  | 5.27|    5H ~ |
| AG_10_3  | 5.27 |   5H ~ |

## Predict & Submission

### Predict

```{python, eval = FALSE} 
X_sub = transformer_ag.transform(test)

sub_model = TabularPredictor.load("model_path")
y_sub = sub_model.predict(X_sub)
```

### Submission

```{python, eval = FALSE} 
submission = pd.read_csv("competition_data/test_data_modified.csv")
submission["RIDE_DEMAND"] = y_sub

submission.to_csv("test_data_modified_submi.csv",index=False)
```







