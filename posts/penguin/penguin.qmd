---
title: "Tensorflow ex"
author: "sungil_park"
date: "2023/03/21"
date-modified: "2023/03/21"
description: "Datamining Basics"
categories: Python
editor_options: 
  chunk_output_type: inline
---

```{r}
```

## 펭귄의 종, 서식지, 부리크기, 날개크기, 성별을 통해 몸무게를 예측하는 딥러닝 회귀 모델

## 데이터 불러오기

seaborn 패키지에 포함된 "penguins" 데이터셋 사용

```{python}
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns

penguins = sns.load_dataset("penguins")          # data 불러오기
penguins = penguins.dropna()     
penguins.head()
```

데이터 정보

```{python}
penguins.info()
```

`species` 별 평균치

```{python}
penguins.groupby('species').mean()
```

`tensorflow` 설치 & 임포트

```{python}
#!pip install tensorflow
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers
```

## 전처리

카테고리형 변수인 `species`, `island`, `sex` 를 더미 변수화를 통해 0,1로 변환

```{python}
penguins_cat = pd.get_dummies(penguins,columns=['species','island','sex'])
penguins_cat.head()
```

성능 검증을 위한 train_set, test_set로 분리

```{python}
train_set = penguins_cat.sample(frac=0.8, random_state=9)
test_set = penguins_cat.drop(train_set.index)

len(train_set),len(test_set)
```
train_set, test_set 에서 종속변수 `body_mass_g`를 분리해 X,y로 만들기
```{python}
X_train = train_set.drop(['body_mass_g'],axis = 1)
y_train = train_set['body_mass_g']
X_test = test_set.drop(['body_mass_g'],axis = 1)
y_test = test_set['body_mass_g']
```

```{python}
X_train.head()
```
데이터를 정규화시켜주는 레이어 `normalizer` 
```{python}
normalizer = tf.keras.layers.Normalization(axis=-1)

normalizer.adapt(np.array(X_train))

print(normalizer.mean.numpy())

```
첫번째 행 데이터와 정규화된 데이터 비교
```{python}
first = np.array(X_train[:1])

with np.printoptions(precision=2, suppress=True):
    print('First example:', first)
    print()
    print('Normalized:', normalizer(first).numpy())

```
## 모델 생성 함수
1번 레이어는 정규화 레이어

각 레이어의 퍼셉트론 개수, 활성함수 지정

마지막 레이어는 1개 퍼셉트론으로 최종 예측값 출력
```{python}
def build_and_compile_model(norm):
    model = keras.Sequential([
          norm,
          layers.Dense(64, activation='relu'),
        layers.Dense(32, activation='relu'),
        layers.Dense(16, activation='relu'),
        layers.Dense(8, activation='relu'),
        layers.Dense(1)
      ])
    
    model.compile(loss='mean_absolute_error',
                optimizer=tf.keras.optimizers.Adam(0.001),
                 metrics = ['mae','mse'])
    return model
  

```

### 모델 생성
```{python}
dnn_model = build_and_compile_model(normalizer)
dnn_model.summary()
```
### 학습
EPOCH = 학습횟수수
```{python}
class PrintDot(keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs):
        if epoch % 100 == 0: print('')
        print('.', end='')

EPOCHS = 1000

history = dnn_model.fit(
    X_train,
    y_train,
    validation_split=0.2,
    verbose=0,epochs=EPOCHS,callbacks=[PrintDot()])
```

### 학습 결과
```{python}
hist = pd.DataFrame(history.history)
hist['epoch'] = history.epoch
hist.tail()
```

```{python}
def plot_history(history):
  plt.cla()
  hist = pd.DataFrame(history.history)
  hist['epoch'] = history.epoch

  plt.plot()
  plt.xlabel('Epoch')
  plt.ylabel('Mean Square Error')
  plt.plot(hist['epoch'], hist['mse'],
         label='Train Error')
  plt.plot(hist['epoch'], hist['val_mse'],
         label = 'Val Error')
    #plt.ylim([0,3000])
  plt.legend()
  plt.show()
```

```{python}
plot_history(history)
```

Validation loss 기준 Early stop옵션 적용 
```{python}
model = build_and_compile_model(normalizer)

early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)

history = model.fit(X_train,
    y_train, epochs=EPOCHS,
                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])

plot_history(history)
```









