[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Sungil_Park",
    "section": "",
    "text": "안녕하세요 박성일 입니다.\n\n\nRstudio를 사용한 Quarto website & blog 만들기 입니다."
  },
  {
    "objectID": "posts/datamining/datamining.html",
    "href": "posts/datamining/datamining.html",
    "title": "Datamining",
    "section": "",
    "text": "import pandas as pd\npd.__version__\n\n'1.5.3'\n\n\n\ns2 = pd.Series([68, 83, 112, 68], index=[\"alice\", \"bob\", \"charles\", \"darwin\"])\ns2\n\nalice       68\nbob         83\ncharles    112\ndarwin      68\ndtype: int64\n\n\n\ns2['bob']\n\n83\n\n\npandas can draw plot\n\nimport matplotlib.pyplot as plt\ntemperatures = [4.4,5.1,6.1,6.2,6.1,6.1,5.7,5.2,4.7,4.1,3.9,3.5]\ns7 = pd.Series(temperatures, name=\"Temperature\")\ns7.plot()\nplt.show()"
  },
  {
    "objectID": "posts/detect_line/detect_line.html",
    "href": "posts/detect_line/detect_line.html",
    "title": "Traffic line detection using CV2",
    "section": "",
    "text": "1.주제 선정\n주제는 ’CV2 활용 차선 탐지’로 최근 자율주행 자동차의 눈이 되는 부분을 이미지분석 수업과정으로 배운 CV2를 활용해 구현할 수 있어 선정하였다.\n\n\n2.이미지 로드 전처리\n프로젝트에 사용한 이미지는 인천대교를 건너는 자동차의 블랙박스 영상이다.\n\n2-1. 원근변환\n\n적색 네 점을 위에서 본 시점으로 변환한다.\ngetPerspectiveTransform함수와, warpPerspective함수를 사용해 원근 변환된 이미지와, 다시 원상복귀시키기 위한 getPerspectiveTransform함수를 역으로 적용시킨 값을 출력한다.\n\n\n2-2 색 범위 탐색\n\n이미지에서 흰색 차선이 있는 곳을 찾기 위해 이미지를 HSV(색상,채도,명도) 형식으로 변환 후 흰색 구간에 부합하는 값을 출력한다.\n\n\n2-3. 관심지역 설정\n\n색 구간으로 흰색을 탐지한 결과 좌상단에 노이즈가 있는 것을 볼 수 있다. 노이즈를 없애기 위해 차선이 있는 구간을 관심지역으로 정해 관심지역 안에서만 탐지하게 한다.\n원본 이미지와 해상도가 동일한 0으로 이루어진 1차원 이미지에 fillpoly함수를 사용하여 관심구간 좌표를 흰색으로 칠한다. 후에 bitwise_and 연산을 이용해 겹치는 구간만을 출력한다.\n\n\n2-4. 흑백화, threshold 연산\n185를 기준으로 threshold 연산을 한 이미지를 출력한다.\n\n\n\n3.탐지구간 분할\n\n3-1. 차선 히스토그램\n전처리 된 1차원 이미지를 행 기준으로 더하여 출력된 리스트를 히스토그램으로 그린후, 히스토그램의 좌측과 우측에서의 최댓값을 가지는 점을 출력한다.\n\n예시 사진에서는 (270,1082) 점에서 최댓값을 가졌다.\n\n\n3-2. 구간 분할 및 탐색\n각 차선을 n개의 구간으로 나누어 좌,우로 125의 마진을 갖는 상자를 그린다. 동영상의 각 프레임에서 상자안에 드는 차선들의 평균값을 리턴한다. 리턴된 값에 Polyfit연산을 사용해 차선의 예측선을 출력한다.\n\n\n\n\n4. 결과 도출\n차선의 예측선 사이를 fillpoly함수를 통해 칠한후, 2-1에서 출력한 원근변환을 이용해 원본 크기로 돌린다. 투명도를 위해 원본 동영상에 addWeighted 연산을 통해 결과 동영상을 출력한다.\n\n\n\n5. 응용 방안\n\n차선의 곡률, 이탈률을 계산하여 차선이탈 경고시스템에 적용 가능하다. 더 나아가 고속도로처럼 차선이 명확한 부분에서는 간단한 자율주행기능에도 적용할 수 있다.\n유사한 방식으로 주차선을 탐지한다면 주차보조 시스템에적용할 수 있다.\n\n\n\n6. 보완해야 할 점\n\n커브길을 진입할 경우에 2-3에서 지정한 관심지역 밖으로 차선이 나가는 경우에는 탐지를 하지 못한다. \n원근변환, 관심지역의 값을 변경해 보완해야 함\n\n\n\n\n그림자가 있거나 갑자기 밝아지는 상황에서 탐지율이 떨어진다. 주변의 밝기를 기준으로 threshold연산을 유동적으로 하여 보완할 필요가 있다.\n\n코드:\nhttps://drive.google.com/drive/folders/1Jfc9HOaVIaTQ48MsyXwG79ePtQIfflnl?usp=sharing\n소스 출처: https://github.com/sidroopdaska/SelfDrivingCar/tree/master/AdvancedLaneLinesDetection\n영상 출처:\nhttps://youtu.be/aItuTJYMj28"
  },
  {
    "objectID": "posts/penguin/penguin.html",
    "href": "posts/penguin/penguin.html",
    "title": "Tensorflow ex",
    "section": "",
    "text": "import seaborn as sns\n\npeng = sns.load_dataset(\"penguins\")          # data 불러오기\npeng = peng.dropna()     \npeng\n\n    species     island  bill_length_mm  ...  flipper_length_mm  body_mass_g     sex\n0    Adelie  Torgersen            39.1  ...              181.0       3750.0    Male\n1    Adelie  Torgersen            39.5  ...              186.0       3800.0  Female\n2    Adelie  Torgersen            40.3  ...              195.0       3250.0  Female\n4    Adelie  Torgersen            36.7  ...              193.0       3450.0  Female\n5    Adelie  Torgersen            39.3  ...              190.0       3650.0    Male\n..      ...        ...             ...  ...                ...          ...     ...\n338  Gentoo     Biscoe            47.2  ...              214.0       4925.0  Female\n340  Gentoo     Biscoe            46.8  ...              215.0       4850.0  Female\n341  Gentoo     Biscoe            50.4  ...              222.0       5750.0    Male\n342  Gentoo     Biscoe            45.2  ...              212.0       5200.0  Female\n343  Gentoo     Biscoe            49.9  ...              213.0       5400.0    Male\n\n[333 rows x 7 columns]\n\n\n\npeng.info()\n\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 333 entries, 0 to 343\nData columns (total 7 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            333 non-null    object \n 1   island             333 non-null    object \n 2   bill_length_mm     333 non-null    float64\n 3   bill_depth_mm      333 non-null    float64\n 4   flipper_length_mm  333 non-null    float64\n 5   body_mass_g        333 non-null    float64\n 6   sex                333 non-null    object \ndtypes: float64(4), object(3)\nmemory usage: 20.8+ KB\n\n\n\npeng.groupby('species').mean()\n\n           bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\nspecies                                                                 \nAdelie          38.823973      18.347260         190.102740  3706.164384\nChinstrap       48.833824      18.420588         195.823529  3733.088235\nGentoo          47.568067      14.996639         217.235294  5092.436975\n\n<string>:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n\n#!pip install tensorflow\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n\npeng_dum = pd.get_dummies(peng,columns=['species','island','sex'])\npeng_dum\n\n     bill_length_mm  bill_depth_mm  ...  sex_Female  sex_Male\n0              39.1           18.7  ...           0         1\n1              39.5           17.4  ...           1         0\n2              40.3           18.0  ...           1         0\n4              36.7           19.3  ...           1         0\n5              39.3           20.6  ...           0         1\n..              ...            ...  ...         ...       ...\n338            47.2           13.7  ...           1         0\n340            46.8           14.3  ...           1         0\n341            50.4           15.7  ...           0         1\n342            45.2           14.8  ...           1         0\n343            49.9           16.1  ...           0         1\n\n[333 rows x 12 columns]\n\n\n\ntrain_set = peng_dum.sample(frac=0.8, random_state=0)\ntest_set = peng_dum.drop(train_set.index)\n\n\nlen(train_set),len(test_set)\n\n(266, 67)\n\n\n\nX_train = train_set.drop(['body_mass_g'],axis = 1)\ny_train = train_set['body_mass_g']\nX_test = test_set.drop(['body_mass_g'],axis = 1)\ny_test = test_set['body_mass_g']\n\n\nX_train\n\n     bill_length_mm  bill_depth_mm  ...  sex_Female  sex_Male\n62             37.6           17.0  ...           1         0\n60             35.7           16.9  ...           1         0\n283            54.3           15.7  ...           0         1\n107            38.2           20.0  ...           0         1\n65             41.6           18.0  ...           0         1\n..              ...            ...  ...         ...       ...\n149            37.8           18.1  ...           0         1\n186            49.7           18.6  ...           0         1\n137            40.2           20.1  ...           0         1\n303            50.0           15.9  ...           0         1\n342            45.2           14.8  ...           1         0\n\n[266 rows x 11 columns]\n\n\n\nnormalizer = tf.keras.layers.Normalization(axis=-1)\n\nnormalizer.adapt(np.array(X_train))\n\nprint(normalizer.mean.numpy())\n\n[[4.3782330e+01 1.7148497e+01 2.0074435e+02 4.5112786e-01 1.9548874e-01\n  3.5338345e-01 5.0000000e-01 3.4962410e-01 1.5037596e-01 5.0375938e-01\n  4.9624062e-01]]\n\n\n\nfirst = np.array(X_train[:1])\n\nwith np.printoptions(precision=2, suppress=True):\n    print('First example:', first)\n    print()\n    print('Normalized:', normalizer(first).numpy())\n\nFirst example: [[ 37.6  17.  185.    1.    0.    0.    1.    0.    0.    1.    0. ]]\n\nNormalized: [[-1.13 -0.08 -1.09  1.1  -0.49 -0.74  1.   -0.73 -0.42  0.99 -0.99]]"
  },
  {
    "objectID": "posts/pizza/pizza.html",
    "href": "posts/pizza/pizza.html",
    "title": "pizza",
    "section": "",
    "text": "Let the radius of the pizza be ‘z’ and the depth be ‘a’.\n\n\nThe volume of the pizza is π * z**2 * a.\npi z z a\ndelicious pizza"
  },
  {
    "objectID": "posts/post-with-code/post_with_code.html",
    "href": "posts/post-with-code/post_with_code.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/py-test/py-test.html#section",
    "href": "posts/py-test/py-test.html#section",
    "title": "Issue Report",
    "section": "2023/03/27",
    "text": "2023/03/27\nQuarto markdown의 코드 청크가 전부 파이썬으로 구성되면 같은 디렉토리에 .ipynb가 생성된다.\nRstudio ipykernel에는 .ipynb를 렌더링 할 수 없기에 에러가 발생한다.\n이에 Quarto markdown 에 비어있는 R코드청크를 넣어두면 .ipynb가 생성되지 않고 렌더링 할 수 있다.\n\n#!pip install matplotlib\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\na = np.arange(-1,1,0.01)\nb = a**2\nplt.plot(a,b)"
  },
  {
    "objectID": "posts/vis/vis.html#section",
    "href": "posts/vis/vis.html#section",
    "title": "training markdown & GGplot",
    "section": "2023/03/15",
    "text": "2023/03/15\ntrain markdown, ggplot\n\nrm(list = ls())\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\n다음의 패키지를 부착합니다: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\ndata_raw <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/mpg.csv\")\ndata_raw %>% dim()\n\n[1] 234  12\n\ndata_raw %>% head()\n\n  X manufacturer model displ year cyl      trans drv cty hwy fl   class\n1 1         audi    a4   1.8 1999   4   auto(l5)   f  18  29  p compact\n2 2         audi    a4   1.8 1999   4 manual(m5)   f  21  29  p compact\n3 3         audi    a4   2.0 2008   4 manual(m6)   f  20  31  p compact\n4 4         audi    a4   2.0 2008   4   auto(av)   f  21  30  p compact\n5 5         audi    a4   2.8 1999   6   auto(l5)   f  16  26  p compact\n6 6         audi    a4   2.8 1999   6 manual(m5)   f  18  26  p compact\n\ndata_raw %>% summary()\n\n       X          manufacturer          model               displ      \n Min.   :  1.00   Length:234         Length:234         Min.   :1.600  \n 1st Qu.: 59.25   Class :character   Class :character   1st Qu.:2.400  \n Median :117.50   Mode  :character   Mode  :character   Median :3.300  \n Mean   :117.50                                         Mean   :3.472  \n 3rd Qu.:175.75                                         3rd Qu.:4.600  \n Max.   :234.00                                         Max.   :7.000  \n      year           cyl           trans               drv           \n Min.   :1999   Min.   :4.000   Length:234         Length:234        \n 1st Qu.:1999   1st Qu.:4.000   Class :character   Class :character  \n Median :2004   Median :6.000   Mode  :character   Mode  :character  \n Mean   :2004   Mean   :5.889                                        \n 3rd Qu.:2008   3rd Qu.:8.000                                        \n Max.   :2008   Max.   :8.000                                        \n      cty             hwy             fl               class          \n Min.   : 9.00   Min.   :12.00   Length:234         Length:234        \n 1st Qu.:14.00   1st Qu.:18.00   Class :character   Class :character  \n Median :17.00   Median :24.00   Mode  :character   Mode  :character  \n Mean   :16.86   Mean   :23.44                                        \n 3rd Qu.:19.00   3rd Qu.:27.00                                        \n Max.   :35.00   Max.   :44.00                                        \n\n\n\ndata_use <- data_raw %>% select(-1)\ndata_use %>% head()\n\n  manufacturer model displ year cyl      trans drv cty hwy fl   class\n1         audi    a4   1.8 1999   4   auto(l5)   f  18  29  p compact\n2         audi    a4   1.8 1999   4 manual(m5)   f  21  29  p compact\n3         audi    a4   2.0 2008   4 manual(m6)   f  20  31  p compact\n4         audi    a4   2.0 2008   4   auto(av)   f  21  30  p compact\n5         audi    a4   2.8 1999   6   auto(l5)   f  16  26  p compact\n6         audi    a4   2.8 1999   6 manual(m5)   f  18  26  p compact\n\n\n\nggplot(data_use, aes(x=displ, y=hwy)) + geom_point()\n\n\n\n\n\nggplot(data_use, aes(x=displ, y=hwy)) + geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\nggplot(data_use, aes(x=displ, y=hwy)) + \n  geom_point() +\n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "posts/vis/vis.html#section-1",
    "href": "posts/vis/vis.html#section-1",
    "title": "training markdown & GGplot",
    "section": "2023/03/20",
    "text": "2023/03/20\nload data\n\ndata_file <- read.csv(\"ncdc_normals.csv\")\n\n\ndim(data_file)\n\n[1] 2745366       6\n\ndata_file %>% head()\n\n   station_id month day temperature flag       date\n1 AQW00061705     1   1        82.4    C 0000-01-01\n2 AQW00061705     1   2        82.4    C 0000-01-02\n3 AQW00061705     1   3        82.4    C 0000-01-03\n4 AQW00061705     1   4        82.4    C 0000-01-04\n5 AQW00061705     1   5        82.4    C 0000-01-05\n6 AQW00061705     1   6        82.4    C 0000-01-06\n\ndata_file %>% sapply(class) # 날짜 형식 변경\n\n station_id       month         day temperature        flag        date \n\"character\"   \"integer\"   \"integer\"   \"numeric\" \"character\" \"character\" \n\n\n\ndata_file$date <- data_file$date %>% as.Date(\"%Y-%m-%d\")\n\n\ndata_file$station_id %>% unique() %>% length()\n\n[1] 7501\n\n\n4개 역만 정해서 join() 사용\n\nstation_loc <- data.frame(station_id = c(\"USW00014819\",\"USC00042319\",\"USW00093107\",\"USW00012918\"),\n                          location = c(\"Chicago\",\"Death valley\",\"San diego\",\"Houston\"))\n\n\ntemps_long <- data_file %>% inner_join(station_loc,by=\"station_id\")\ntemps_long %>% head()\n\n   station_id month day temperature flag       date     location\n1 USC00042319     1   1        51.0    S 0000-01-01 Death valley\n2 USC00042319     1   2        51.2    S 0000-01-02 Death valley\n3 USC00042319     1   3        51.3    S 0000-01-03 Death valley\n4 USC00042319     1   4        51.4    S 0000-01-04 Death valley\n5 USC00042319     1   5        51.6    S 0000-01-05 Death valley\n6 USC00042319     1   6        51.7    S 0000-01-06 Death valley\n\n\n\nggplot(temps_long, aes(x=date,y=temperature,color=location))+geom_line()\n\n\n\n\n#x축에 표시할 눈금\n\ndate_s <- \"0000-01-01\" %>% as.Date(\"%Y-%m-%d\")  #Y는 대문자\ndate_e <- \"0001-01-01\" %>% as.Date(\"%Y-%m-%d\")\nbreak_date <- seq.Date(date_s, date_e, by = \"3 month\")\n\n\nggplot(temps_long, aes(x=date, y=temperature, color=location))+\n  geom_line()+\n  scale_x_date(name=\"month\", \n               breaks = break_date,\n               labels = c(\"jan\", \"apr\", \"jul\", \"oct\", \"jan\"))+\n  theme_light()\n\n\n\n\n\nggplot(temps_long, aes(x=date, y=temperature, color=location))+\n  geom_line()+\n  scale_y_continuous(name = \"temp\",\n                     limits = c(0,100))+\n  theme_light()\n\n\n\n\n\nggplot(temps_long, aes(x=date, y=temperature, color=location))+\n  geom_line()+\n  scale_x_date(name=\"month\", \n               breaks = break_date,\n               labels = c(\"jan\", \"apr\", \"jul\", \"oct\", \"jan\"))+\n  theme_light()+\n  labs(title = \"Fig 2.3\", subtitle = \"www\", caption = \"eee\", tag = \"rrr\")\n\n\n\n\n\n2021년 서울, 대전, 세종, 제주 기온 데이터\n\ndata_2021 <- read.csv(\"https://raw.githubusercontent.com/Sungileo/trainsets/main/OBS_ASOS_DD_20220308125952.csv\", fileEncoding = \"euc-kr\")\n\n자료형 확인\n\ndata_2021 %>% dim()\n\n[1] 1460    6\n\ndata_2021 %>% head()\n\n  지점 지점명       일시 평균기온..C. 최저기온..C. 최고기온..C.\n1  108   서울 2021-01-01         -4.2         -9.8          1.6\n2  108   서울 2021-01-02         -5.0         -8.4         -1.4\n3  108   서울 2021-01-03         -5.6         -9.1         -2.0\n4  108   서울 2021-01-04         -3.5         -8.4          0.3\n5  108   서울 2021-01-05         -5.5         -9.9         -2.1\n6  108   서울 2021-01-06         -7.4        -12.0         -1.9\n\ndata_2021 %>% sapply(class)\n\n        지점       지점명         일시 평균기온..C. 최저기온..C. 최고기온..C. \n   \"integer\"  \"character\"  \"character\"    \"numeric\"    \"numeric\"    \"numeric\" \n\n\n일시 자료형을 date형태로 바꾸기\n\ndata_2021$일시 <-data_2021$일시 %>% as.Date(\"%Y-%m-%d\")\ndata_2021 %>% sapply(class)\n\n        지점       지점명         일시 평균기온..C. 최저기온..C. 최고기온..C. \n   \"integer\"  \"character\"       \"Date\"    \"numeric\"    \"numeric\"    \"numeric\" \n\n\n기초통계량 확인\n\ndata_2021 %>% summary()\n\n      지점          지점명               일시             평균기온..C.   \n Min.   :108.0   Length:1460        Min.   :2021-01-01   Min.   :-14.90  \n 1st Qu.:126.8   Class :character   1st Qu.:2021-04-02   1st Qu.:  7.90  \n Median :158.5   Mode  :character   Median :2021-07-02   Median : 15.00  \n Mean   :166.0                      Mean   :2021-07-02   Mean   : 14.77  \n 3rd Qu.:197.8                      3rd Qu.:2021-10-01   3rd Qu.: 23.10  \n Max.   :239.0                      Max.   :2021-12-31   Max.   : 31.70  \n  최저기온..C.     최고기온..C.   \n Min.   :-19.10   Min.   :-10.70  \n 1st Qu.:  3.10   1st Qu.: 13.18  \n Median : 11.10   Median : 20.15  \n Mean   : 10.69   Mean   : 19.56  \n 3rd Qu.: 19.60   3rd Qu.: 27.70  \n Max.   : 28.10   Max.   : 36.50  \n\n\nbreaks 설정\n\ndate_21s <- \"2021-01-01\" %>% as.Date(\"%Y-%m-%d\")  #Y는 대문자\ndate_21e <- \"2022-01-01\" %>% as.Date(\"%Y-%m-%d\")\nbreak_date_21 <- seq.Date(date_21s, date_21e, by = \"3 month\")\n\nploting\n\n#data_2021 %>% names()\nggplot(data_2021,aes(x = 일시,y = 평균기온..C., color = 지점명))+\n  geom_line(linewidth = 1) +\n  scale_x_date(name =\"월\", \n               breaks = break_date_21,\n               labels = c(\"1월\",\"4월\",\"7월\",\"10월\",\"1월\")) +\n  scale_y_continuous(name = \"평균기온\")+\n  theme_light()\n\n\n\n\n\n\n2022년 서울, 대전, 세종, 제주 기온 데이터\n\ndata_2022 <- read.csv(\"https://raw.githubusercontent.com/Sungileo/trainsets/main/OBS_ASOS_DD_20230322080932.csv\", fileEncoding = \"euc-kr\")\n\n자료형 확인\n\ndata_2022 %>% dim()\n\n[1] 2555    6\n\ndata_2022 %>% head()\n\n  지점 지점명       일시 평균기온..C. 최저기온..C. 최고기온..C.\n1  108   서울 2022-01-01         -4.3        -10.2          2.3\n2  108   서울 2022-01-02         -1.3         -5.2          3.0\n3  108   서울 2022-01-03         -1.9         -8.0          2.5\n4  108   서울 2022-01-04         -2.5         -5.6          1.0\n5  108   서울 2022-01-05         -2.8         -7.8          1.9\n6  108   서울 2022-01-06         -2.2         -5.9          3.3\n\ndata_2022 %>% sapply(class)\n\n        지점       지점명         일시 평균기온..C. 최저기온..C. 최고기온..C. \n   \"integer\"  \"character\"  \"character\"    \"numeric\"    \"numeric\"    \"numeric\" \n\n\n일시 자료형을 date형태로 바꾸기\n\ndata_2022$일시 <-data_2022$일시 %>% as.Date(\"%Y-%m-%d\")\ndata_2022 %>% sapply(class)\n\n        지점       지점명         일시 평균기온..C. 최저기온..C. 최고기온..C. \n   \"integer\"  \"character\"       \"Date\"    \"numeric\"    \"numeric\"    \"numeric\" \n\n\n기초통계량 확인\n\ndata_2022 %>% summary()\n\n      지점          지점명               일시             평균기온..C.   \n Min.   :108.0   Length:2555        Min.   :2022-01-01   Min.   :-11.80  \n 1st Qu.:133.0   Class :character   1st Qu.:2022-04-02   1st Qu.:  8.20  \n Median :185.0   Mode  :character   Median :2022-07-02   Median : 16.40  \n Mean   :175.1                      Mean   :2022-07-02   Mean   : 15.27  \n 3rd Qu.:189.0                      3rd Qu.:2022-10-01   3rd Qu.: 23.00  \n Max.   :239.0                      Max.   :2022-12-31   Max.   : 32.20  \n                                                         NA's   :2       \n  최저기온..C.      최고기온..C.  \n Min.   :-13.800   Min.   :-8.60  \n 1st Qu.:  4.225   1st Qu.:12.30  \n Median : 12.600   Median :20.75  \n Mean   : 11.626   Mean   :19.49  \n 3rd Qu.: 19.800   3rd Qu.:27.20  \n Max.   : 28.900   Max.   :37.50  \n NA's   :1         NA's   :1      \n\n\nbreaks 설정\n\ndate_22s <- \"2022-01-01\" %>% as.Date(\"%Y-%m-%d\")  #Y는 대문자\ndate_22e <- \"2023-01-01\" %>% as.Date(\"%Y-%m-%d\")\nbreak_date_22 <- seq.Date(date_22s, date_22e, by = \"3 month\")\n\nploting\n\n#data_2021 %>% names()\nggplot(data_2022,aes(x = 일시,y = 평균기온..C., color = 지점명))+\n  geom_line(linewidth = 1) +\n  scale_x_date(name =\"월\", \n               breaks = break_date_22,\n               labels = c(\"1월\",\"4월\",\"7월\",\"10월\",\"1월\")) +\n  scale_y_continuous(name = \"평균기온\")+\n  theme_light()\n\n\n\n\n\nmean_temps <- temps_long %>% \n  group_by(month,location) %>% \n  summarise(mean = mean(temperature)) %>% \n  ungroup() %>% \n  mutate(month = factor(month %>% paste(),\n                        levels = 1:12 %>% paste()))\n\n`summarise()` has grouped output by 'month'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "posts/vis/vis.html#section-2",
    "href": "posts/vis/vis.html#section-2",
    "title": "training markdown & GGplot",
    "section": "2023/03/27",
    "text": "2023/03/27\n\nggplot(mean_temps,aes(x = month, y = location, fill = mean))+\n  geom_tile(width = .95,height = 0.95)+\n  scale_fill_viridis_c(option = \"B\",begin = 0.15, end = 0.98,\n                       name = \"temperature\")+\n  coord_fixed(expand = FALSE)+\n  ylab(NULL)"
  },
  {
    "objectID": "posts/vis/vis.html#section-3",
    "href": "posts/vis/vis.html#section-3",
    "title": "training markdown & GGplot",
    "section": "2023/03/29",
    "text": "2023/03/29\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\n\ndata_file <- read.csv(\"ncdc_normals.csv\")\ndata_file$date <- data_file$date %>% as.Date(\"%Y-%m-%d\")\n\nhouston <- data.frame(station_id = c(\"USW00012918\"), location = c(\"Houston\"))\n\nhouston_temps <- data_file %>% inner_join(houston,by=\"station_id\")\nhouston_temps %>% head()\n\n   station_id month day temperature flag       date location\n1 USW00012918     1   1        53.9    S 0000-01-01  Houston\n2 USW00012918     1   2        53.8    S 0000-01-02  Houston\n3 USW00012918     1   3        53.8    S 0000-01-03  Houston\n4 USW00012918     1   4        53.8    S 0000-01-04  Houston\n5 USW00012918     1   5        53.8    S 0000-01-05  Houston\n6 USW00012918     1   6        53.7    S 0000-01-06  Houston\n\n\n\ndate_s <- \"0000-01-01\" %>% as.Date(\"%Y-%m-%d\")  #Y는 대문자\ndate_e <- \"0001-01-01\" %>% as.Date(\"%Y-%m-%d\")\nbreak_date <- seq.Date(date_s, date_e, by = \"3 month\")\n\n\nggplot(houston_temps, aes(x=date, y=temperature,color = location))+\n  geom_line(size = 1,color = \"royalblue\")+\n  scale_x_date(name=\"month\", \n               breaks = break_date,\n               labels = c(\"jan\", \"apr\", \"jul\", \"oct\", \"jan\"))+\n  theme_light()+\n  ylab(\"Temperature(℉)\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n#install.packages(\"cowplot\")\nlibrary(cowplot)\n\nWarning: 패키지 'cowplot'는 R 버전 4.2.3에서 작성되었습니다\n\n\n\nhouston_plot <- ggplot(houston_temps, aes(x=date, y=temperature,color = location))+\n  geom_line(size = 1,color = \"royalblue\")+\n  scale_x_date(name=\"month\", \n               breaks = break_date,\n               labels = c(\"jan\", \"apr\", \"jul\", \"oct\", \"jan\"))+\n  theme_light()+\n  ylab(\"Temperature(℉)\")\n\narrange multiple plots into a grid\n\nplot_ab <- plot_grid(houston_plot,houston_plot,\n                    nrow = 1,\n                    rel_widths = c(1,2),\n                    labels = c(\"a\",\"b\"))\n\nplot_abc <- plot_grid(plot_ab, houston_plot,\n                      ncol = 1,\n                      rel_heights = c(1.5,2),\n                      labels = c(\"\",\"c\"))\n\nplot_abc\n\n\n\n\n\ntexas_cnt <- read.csv(\"https://raw.githubusercontent.com/christianmendoza/texas-counties/main/data/texas-counties.csv\")\n\ntx_counties <- texas_cnt %>% \n  select(county,population) %>% \n  mutate(county = gsub(\"county\",\"\",county),\n         popratio = population/median(population)) %>% \n  arrange(desc(popratio)) %>% \n  mutate(index = 1:n(),\n         label = ifelse(index<=3|index>n()-3|runif(n())<.04, county, \"\"))\n\nrunif(x) x 0~1 사이의 난수\n\ntx_counties\n\n           county population     popratio index         label\n1          Harris    4728030 2.564286e+02     1        Harris\n2          Dallas    2586050 1.402565e+02     2        Dallas\n3         Tarrant    2126477 1.153312e+02     3       Tarrant\n4           Bexar    2028236 1.100030e+02     4              \n5          Travis    1305154 7.078609e+01     5        Travis\n6          Collin    1109462 6.017258e+01     6              \n7          Denton     941647 5.107099e+01     7              \n8         Hidalgo     880356 4.774683e+01     8              \n9         El Paso     867947 4.707381e+01     9              \n10      Fort Bend     858527 4.656291e+01    10     Fort Bend\n11     Montgomery     648886 3.519286e+01    11              \n12     Williamson     643026 3.487504e+01    12              \n13        Cameron     423029 2.294332e+01    13              \n14       Brazoria     379689 2.059274e+01    14              \n15           Bell     379617 2.058884e+01    15              \n16      Galveston     355062 1.925708e+01    16              \n17         Nueces     353079 1.914953e+01    17              \n18        Lubbock     314451 1.705451e+01    18              \n19           Webb     267945 1.453222e+01    19              \n20       McLennan     263115 1.427026e+01    20              \n21           Hays     255397 1.385167e+01    21              \n22      Jefferson     253704 1.375984e+01    22              \n23          Smith     237186 1.286398e+01    23              \n24         Brazos     237032 1.285562e+01    24              \n25          Ellis     202678 1.099241e+01    25              \n26        Johnson     187280 1.015728e+01    26              \n27      Guadalupe     177036 9.601692e+00    27              \n28          Comal     174986 9.490509e+00    28              \n29        Midland     167969 9.109936e+00    29              \n30          Ector     161091 8.736902e+00    30              \n31        Kaufman     157768 8.556676e+00    31              \n32         Parker     156764 8.502224e+00    32              \n33        Randall     143854 7.802039e+00    33              \n34         Taylor     143326 7.773403e+00    34              \n35        Grayson     139336 7.557002e+00    35              \n36        Wichita     130069 7.054399e+00    36              \n37          Gregg     124201 6.736143e+00    37              \n38      Tom Green     119411 6.476353e+00    38              \n39         Potter     116547 6.321022e+00    39              \n40       Rockwall     116381 6.312019e+00    40              \n41           Hunt     103394 5.607658e+00    41              \n42        Bastrop     102058 5.535199e+00    42       Bastrop\n43        Liberty      97621 5.294555e+00    43              \n44          Bowie      92581 5.021206e+00    44              \n45       Victoria      90964 4.933507e+00    45              \n46       Angelina      86506 4.691724e+00    46              \n47         Orange      84742 4.596052e+00    47              \n48        Coryell      84232 4.568391e+00    48              \n49      Henderson      83667 4.537748e+00    49              \n50         Walker      77977 4.229146e+00    50        Walker\n51           Wise      71714 3.889467e+00    51              \n52   San Patricio      69699 3.780182e+00    52              \n53       Harrison      69150 3.750407e+00    53              \n54          Starr      66049 3.582221e+00    54              \n55    Nacogdoches      64668 3.507322e+00    55              \n56           Hood      64222 3.483133e+00    56              \n57      Van Zandt      61275 3.323300e+00    57              \n58         Waller      59781 3.242271e+00    58              \n59       Anderson      58402 3.167480e+00    59              \n60       Maverick      58056 3.148715e+00    60              \n61         Hardin      56973 3.089977e+00    61              \n62        Navarro      53591 2.906552e+00    62              \n63           Kerr      53161 2.883230e+00    63              \n64           Rusk      52743 2.860560e+00    64              \n65         Medina      51981 2.819232e+00    65              \n66           Polk      51899 2.814785e+00    66              \n67         Wilson      51257 2.779965e+00    67              \n68       Cherokee      51097 2.771288e+00    68              \n69         Burnet      50954 2.763532e+00    69              \n70          Lamar      50098 2.717106e+00    70              \n71       Atascosa      49939 2.708482e+00    71              \n72       Chambers      48865 2.650233e+00    72              \n73      Val Verde      47564 2.579672e+00    73              \n74       Caldwell      46791 2.537748e+00    74              \n75        Kendall      46788 2.537585e+00    75              \n76           Wood      45875 2.488068e+00    76              \n77          Erath      43378 2.352641e+00    77         Erath\n78          Cooke      42244 2.291138e+00    78              \n79         Upshur      41774 2.265647e+00    79              \n80        Wharton      41721 2.262773e+00    80              \n81      Jim Wells      38847 2.106899e+00    81              \n82          Brown      38192 2.071374e+00    82              \n83        Hopkins      37211 2.018169e+00    83              \n84         Fannin      36569 1.983350e+00    84              \n85           Hill      36471 1.978034e+00    85              \n86      Matagorda      36344 1.971147e+00    86              \n87     Washington      35891 1.946578e+00    87              \n88         Howard      34128 1.850960e+00    88              \n89         Jasper      32975 1.788426e+00    89              \n90           Hale      32220 1.747478e+00    90              \n91          Titus      31183 1.691235e+00    91              \n92            Bee      30924 1.677188e+00    92              \n93        Kleberg      30635 1.661514e+00    93              \n94         Austin      30380 1.647684e+00    94              \n95         Grimes      30287 1.642640e+00    95              \n96     Palo Pinto      28686 1.555809e+00    96              \n97           Cass      28560 1.548975e+00    97              \n98    San Jacinto      27878 1.511986e+00    98              \n99      Gillespie      27297 1.480475e+00    99              \n100         Milam      25106 1.361644e+00   100              \n101        Uvalde      24729 1.341198e+00   101              \n102       Fayette      24687 1.338920e+00   102              \n103       Aransas      24510 1.329320e+00   103              \n104        Shelby      23939 1.298351e+00   104              \n105        Panola      22675 1.229797e+00   105              \n106      Lampasas      22252 1.206855e+00   106              \n107       Houston      22241 1.206259e+00   107              \n108     Limestone      22119 1.199642e+00   108              \n109         Llano      21978 1.191995e+00   109              \n110        Gaines      21895 1.187493e+00   110              \n111       Bandera      21565 1.169595e+00   111              \n112       Hockley      21363 1.158640e+00   112              \n113         Moore      21118 1.145352e+00   113              \n114          Gray      21030 1.140579e+00   114              \n115      Colorado      20630 1.118885e+00   115              \n116        Lavaca      20544 1.114221e+00   116              \n117    Hutchinson      20495 1.111563e+00   117              \n118      Montague      20409 1.106899e+00   118              \n119       Willacy      20316 1.101855e+00   119              \n120         Tyler      20077 1.088893e+00   120              \n121        DeWitt      19918 1.080269e+00   121              \n122         Jones      19873 1.077828e+00   122              \n123     Freestone      19774 1.072459e+00   123              \n124       Calhoun      19727 1.069910e+00   124              \n125      Gonzales      19641 1.065246e+00   125              \n126        Bosque      18503 1.003525e+00   126              \n127       Andrews      18440 1.000108e+00   127              \n128          Frio      18436 9.998915e-01   128              \n129    Deaf Smith      18329 9.940883e-01   129              \n130      Burleson      18051 9.790107e-01   130              \n131         Young      17977 9.749973e-01   131              \n132      Eastland      17864 9.688686e-01   132              \n133           Lee      17706 9.602994e-01   133              \n134         Falls      17313 9.389847e-01   134              \n135     Robertson      16958 9.197310e-01   135              \n136        Scurry      16824 9.124634e-01   136              \n137          Leon      15959 8.655494e-01   137              \n138       Jackson      15121 8.200998e-01   138              \n139         Pecos      15118 8.199371e-01   139              \n140        Karnes      14754 8.001952e-01   140              \n141         Nolan      14597 7.916802e-01   141              \n142        Reeves      14487 7.857143e-01   142              \n143      Callahan      14115 7.655386e-01   143              \n144        Zapata      13908 7.543117e-01   144              \n145       Trinity      13827 7.499186e-01   145              \n146      Comanche      13775 7.470984e-01   146              \n147       Madison      13718 7.440069e-01   147              \n148          Lamb      12898 6.995336e-01   148              \n149     Wilbarger      12731 6.904762e-01   149              \n150          Camp      12616 6.842391e-01   150              \n151         Rains      12509 6.784358e-01   151              \n152        Dawson      12413 6.732292e-01   152              \n153        Newton      12241 6.639006e-01   153              \n154        Morris      12030 6.524569e-01   154              \n155        Blanco      11886 6.446469e-01   155              \n156         Terry      11754 6.374878e-01   156              \n157     Red River      11555 6.266949e-01   157              \n158      Live Oak      11377 6.170409e-01   158              \n159          Ward      11194 6.071157e-01   159              \n160      Franklin      10464 5.675236e-01   160              \n161          Clay      10263 5.566222e-01   161              \n162        Sabine      10039 5.444734e-01   162              \n163       Runnels       9943 5.392667e-01   163              \n164        Parmer       9813 5.322161e-01   164              \n165     Ochiltree       9782 5.305348e-01   165              \n166         Duval       9756 5.291246e-01   166              \n167        Marion       9645 5.231045e-01   167              \n168        Zavala       9534 5.170843e-01   168              \n169     Somervell       9469 5.135590e-01   169              \n170      Brewster       9450 5.125285e-01   170      Brewster\n171      Stephens       9173 4.975052e-01   171              \n172      Mitchell       9070 4.919189e-01   172              \n173          Jack       8712 4.725024e-01   173              \n174        Archer       8681 4.708211e-01   174              \n175        Dimmit       8473 4.595401e-01   175              \n176      Hamilton       8229 4.463065e-01   176              \n177 San Augustine       7922 4.296561e-01   177 San Augustine\n178       Coleman       7735 4.195140e-01   178       Coleman\n179        Yoakum       7607 4.125719e-01   179              \n180     McCulloch       7533 4.085584e-01   180              \n181       Winkler       7415 4.021586e-01   181              \n182        Castro       7374 3.999349e-01   182              \n183        Dallam       7172 3.889793e-01   183              \n184        Goliad       7163 3.884912e-01   184              \n185       Swisher       7008 3.800846e-01   185              \n186        Brooks       6994 3.793253e-01   186              \n187        Bailey       6835 3.707018e-01   187              \n188       Refugio       6756 3.664172e-01   188              \n189     Childress       6736 3.653325e-01   189              \n190      La Salle       6670 3.617529e-01   190              \n191      Presidio       6140 3.330079e-01   191              \n192         Garza       5863 3.179846e-01   192              \n193      San Saba       5827 3.160321e-01   193      San Saba\n194        Carson       5746 3.116390e-01   194              \n195          Lynn       5688 3.084933e-01   195          Lynn\n196       Haskell       5411 2.934700e-01   196              \n197       Hartley       5397 2.927107e-01   197              \n198         Delta       5392 2.924395e-01   198              \n199         Floyd       5350 2.901616e-01   199              \n200        Martin       5211 2.826228e-01   200              \n201      Hansford       5159 2.798026e-01   201              \n202        Crosby       5106 2.769281e-01   202              \n203       Wheeler       4927 2.672199e-01   203              \n204      Jim Hogg       4801 2.603862e-01   204      Jim Hogg\n205         Crane       4680 2.538236e-01   205              \n206         Mills       4480 2.429765e-01   206              \n207        Kimble       4365 2.367393e-01   207              \n208         Mason       3943 2.138518e-01   208              \n209        Fisher       3706 2.009979e-01   209              \n210      Hardeman       3552 1.926456e-01   210              \n211        Baylor       3477 1.885779e-01   211              \n212          Knox       3351 1.817442e-01   212              \n213        Concho       3341 1.812019e-01   213              \n214          Coke       3321 1.801171e-01   214              \n215        Sutton       3319 1.800087e-01   215              \n216      Hudspeth       3287 1.782731e-01   216              \n217      Hemphill       3271 1.774054e-01   217              \n218        Donley       3268 1.772427e-01   218              \n219         Upton       3265 1.770799e-01   219              \n220        Reagan       3253 1.764291e-01   220              \n221   Shackelford       3212 1.742054e-01   221              \n222        Kinney       3130 1.697581e-01   222              \n223      Crockett       3068 1.663955e-01   223              \n224      Lipscomb       2931 1.589652e-01   224              \n225          Hall       2845 1.543009e-01   225              \n226          Real       2826 1.532704e-01   226              \n227       Sherman       2798 1.517518e-01   227              \n228 Collingsworth       2615 1.418267e-01   228              \n229       Cochran       2516 1.364573e-01   229              \n230    Schleicher       2429 1.317388e-01   230              \n231     Culberson       2193 1.189391e-01   231              \n232        Menard       1982 1.074954e-01   232              \n233    Jeff Davis       1949 1.057056e-01   233              \n234     Armstrong       1839 9.973967e-02   234              \n235       Dickens       1740 9.437032e-02   235              \n236        Oldham       1717 9.312290e-02   236              \n237         Irion       1552 8.417399e-02   237              \n238  Throckmorton       1495 8.108255e-02   238              \n239       Edwards       1438 7.799111e-02   239              \n240       Briscoe       1403 7.609285e-02   240              \n241        Cottle       1381 7.489966e-02   241              \n242      Sterling       1381 7.489966e-02   242              \n243     Stonewall       1217 6.600499e-02   243              \n244     Glasscock       1149 6.231695e-02   244              \n245         Foard       1080 5.857468e-02   245              \n246        Motley       1067 5.786962e-02   246              \n247       Roberts        797 4.322595e-02   247              \n248          Kent        749 4.062263e-02   248              \n249       Terrell        724 3.926673e-02   249              \n250        Borden        617 3.346350e-02   250              \n251      McMullen        608 3.297538e-02   251              \n252        Kenedy        340 1.844018e-02   252        Kenedy\n253          King        258 1.399284e-02   253          King\n254        Loving         57 3.091442e-03   254        Loving\n\n\n\n#install.packages(\"ggrepel\")\nlibrary(ggrepel)\n\nWarning: 패키지 'ggrepel'는 R 버전 4.2.3에서 작성되었습니다\n\n\n\nggplot(tx_counties,aes(x=index,y=popratio))+\n  geom_point(size = 1, color = \"royalblue\")+\n  geom_text_repel(aes(label = label),\n                  min.segment.length = 0,\n                  max.overlaps = 100)+\n  theme_light()+\n  theme(panel.border = element_blank())\n\n\n\n\n\nlabel_log10 <- sapply(-2:2,function(i) as.expression(bquote(10^ .(i))))\n\nggplot(tx_counties,aes(x=index,y=popratio))+\n  geom_point(size = 1, color = \"royalblue\")+\n  geom_text_repel(aes(label = label),\n                  min.segment.length = 0,\n                  max.overlaps = 100)+\n  scale_y_log10(name = \"popnum / med\",\n                breaks = 10^(-2:2),\n                labels = label_log10)+\n  theme_light()+\n  theme(panel.border = element_blank())"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Datamining\n\n\n\n\n\n\n\nPython\n\n\n\n\nDatamining Basics\n\n\n\n\n\n\nMar 28, 2023\n\n\nsungil_park\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIssue Report\n\n\n\n\n\n\n\nIssue Report\n\n\n\n\n에잇!\n\n\n\n\n\n\nMar 27, 2023\n\n\nsungil_park\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTensorflow ex\n\n\n\n\n\n\n\nPython\n\n\n\n\nDatamining Basics\n\n\n\n\n\n\nMar 21, 2023\n\n\nsungil_park\n\n\n\n\n\n\n  \n\n\n\n\nTraffic line detection using CV2\n\n\n\n\n\n\n\nPython\n\n\n\n\nPython, cv2\n\n\n\n\n\n\nMar 18, 2023\n\n\nsungil_park\n\n\n\n\n\n\n  \n\n\n\n\ntraining markdown & GGplot\n\n\n\n\n\n\n\nRstudio\n\n\n\n\nData Visualization\n\n\n\n\n\n\nMar 15, 2023\n\n\nsungil_park\n\n\n\n\n\n\n  \n\n\n\n\npizza\n\n\n\n\n\nPost\n\n\n\n\n\n\nMar 14, 2023\n\n\nsungil_park\n\n\n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\n\n\n\n\n\nMar 10, 2023\n\n\nHarlow Malloc\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "recordings.html",
    "href": "recordings.html",
    "title": "Recordings",
    "section": "",
    "text": "Running\n\n\n\nAthletics\n\n\n\nRunning\n\n\n\nsungil_park\n\n\nMar 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStress is water soluble\n\n\n\nAthletics\n\n\n\nSwimming\n\n\n\nsungil_park\n\n\nMar 1, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "records/running.html",
    "href": "records/running.html",
    "title": "Running",
    "section": "",
    "text": "Updates at weekend\n\n\nRecord with Galaxy Watch 4\n\n\nGears\n\nNIKE Air Zoom Tempo NEXT% Flyknit\nNIKE Epic React Flyknit 1\n\n\n\n\nDate\nDistance(km)\nTime\nPace(/1km)\n\n\n\n\n2023/03/25\n4.2\n30:16\nTreadmil\n\n\n2023/03/24\n3.54\n23:25\n6’36\n\n\n2023/03/19\n3.01\n15:36\n5’10\n\n\n2023/03/17\n3.03\n17:55\n5’54\n\n\n2023/03/15\n3.38\n23:21\n6’54\n\n\n2023/03/05\n4.14\n30:30\n7’20"
  },
  {
    "objectID": "records/Swimming.html",
    "href": "records/Swimming.html",
    "title": "Stress is water soluble",
    "section": "",
    "text": "Updates at weekend\n\n\nRecord with Galaxy Watch 4\n\n\nGears\n\nSPEEDO Allover V-cut Jammer\nNIKE have a Nike day Swimming cap\nNIKE Vapor Mirrored Performance Goggle\n\n\n\n\nDate\nDistance(m)\nTime\nPace(/100m)\nReview\n\n\n\n\n2023/03/30\n700\n15:52\n2’07\nRecovery day\n\n\n2023/03/29\n2800\n51:31\n1’07\nOpenwater week6\n\n\n2023/03/23\n600\n28:59\n1’52\nRecovery day\n\n\n2023/03/22\n3050\n56:50\n1’38\nOpenwater Week5\n\n\n2023/03/21\n900\n18:53\n1’59\nRecovery day\n\n\n2023/03/20\n2100\n42:57\n2’02\n1800m\n\n\n2023/03/18\n1600\n29:31\n1’50\n50m Dash PR 42sec\n\n\n2023/03/16\n1800\n35:42\n1’58\ngood\n\n\n2023/03/14\n700\n13:52\n1’58\nDNF 40m Success\n\n\n2023/03/13\n1300\n26:25\n2’01\n\n\n\n2023/03/12\n1050\n27:28\n1’44\n\n\n\n2023/03/10\n1500\n30:00\n1’59\n1500m/30min Success\n\n\n2023/03/07\n2000\n41:52\n2’05\n\n\n\n2023/03/06\n1350\n27:28\n2’00\n\n\n\n2023/03/04\n450\n9:42\n2’06\nRecovery day\n\n\n2023/03/03\n1950\n50:13\n2’16\n\n\n\n2023/03/01\n3100\n65:00\n2’05\n3.1 to 3.1km"
  }
]